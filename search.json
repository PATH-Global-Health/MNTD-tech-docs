[
  {
    "objectID": "posts/rainfall/index.html",
    "href": "posts/rainfall/index.html",
    "title": "Downloading CHIRPS rainfall data",
    "section": "",
    "text": "The Climate Hazards Group InfraRed Precipitation with Station data (CHIRPS) is a quasi-global rainfall dataset spanning 1981 to present. The rainfall data is available as daily, pentadaily (5-day), and monthly raster files at a resolution of 0.05°. This post covers how to obtain CHIRPS data using the PATHtools package for projects requiring areal data, e.g., summary data for health districts or regions. It also provides a brief introduction to the chirps R package, which downloads data at user-defined points, e.g., health facilities or households.\nLearn more about CHIRPS at UCSB’s Climate Hazards Center."
  },
  {
    "objectID": "posts/rainfall/index.html#areal-data",
    "href": "posts/rainfall/index.html#areal-data",
    "title": "Downloading CHIRPS rainfall data",
    "section": "Areal data",
    "text": "Areal data\nThe PATHtools rainfall() function allows you to extract estimates of average rainfall across one or more areas saved as project shapefiles. First, install PATHtools.\n\ninstall.packages(\"devtools\", repos = \"http://cran.us.r-project.org\")\n\npackage 'devtools' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\eferriss\\AppData\\Local\\Temp\\RtmpwjwdPW\\downloaded_packages\n\ndevtools::install_github(\"PATH-Global-Health/PATHtools\")\n\nNext, read in a shapefile of Zambia’s provinces from the package and obtain daily rainfall estimates for each polygon (province). Note the arguments for the daily_rainfall() function: The start_date and end_date are the beginning and end boundaries of your time period, and must be supplied in “YYYY-MM-DD” format. The shapefile shp should be an sf object of the POLYGON or MULTIPOLYGON class.\n\nlibrary(PATHtools)\n\n#Load shapefile\nshp <- load_shapefile(country = \"Zambia\", admin_level = 1)\n\n#Obtain daily rainfall for 2012-01-01 through 2012-01-31 in WIDE FORMAT\nstart_date <- \"2012-01-01\"\nend_date <- \"2012-01-31\"\nrain_areal <- daily_rainfall(c(start_date, end_date),shp)\n\n#View rainfall data for first 5 days\nrain_areal[,1:6]\n\n# A tibble: 10 × 6\n   ADM1         `chirps_2012-01-01` `chirps_2012-01-02` chirps…¹ chirp…² chirp…³\n   <chr>                      <dbl>               <dbl>    <dbl>   <dbl>   <dbl>\n 1 Central                   17.0                12.5     1.66    0.0755  0.783 \n 2 Copperbelt                23.1                 6.61    1.59    1.06    4.49  \n 3 Eastern                   15.3                28.4     5.44    3.35   14.0   \n 4 Luapula                    2.52                3.81    2.97   16.5     6.14  \n 5 Lusaka                    17.6                 8.10    0.332   0       0     \n 6 Muchinga                   4.34                8.79    9.76   11.3     9.30  \n 7 Northern                   0.219               2.43    2.39   19.8    11.1   \n 8 Northwestern               7.48                6.93    4.14    1.34    1.33  \n 9 Southern                  13.2                 0.784   0.0663  0       0.0169\n10 Western                    6.81                4.67    0.210   0.634   0     \n# … with abbreviated variable names ¹​`chirps_2012-01-03`, ²​`chirps_2012-01-04`,\n#   ³​`chirps_2012-01-05`\n\n\nThe default data format from daily_rainfall() is wide. To obtain the data in long format, set the argument long equal to TRUE.\n\n#Obtain daily rainfall for 2012-01-01 through 2012-01-31 in LONG FORMAT\nrain_areal_long <- daily_rainfall(c(start_date, end_date),shp, long = TRUE)\n\n#View rainfall data for first 5 days in Central Province\nrain_areal_long[1:5,]\n\n# A tibble: 5 × 3\n  ADM1    date       rainfall\n  <chr>   <date>        <dbl>\n1 Central 2012-01-01  17.0   \n2 Central 2012-01-02  12.5   \n3 Central 2012-01-03   1.66  \n4 Central 2012-01-04   0.0755\n5 Central 2012-01-05   0.783 \n\n\nFinally, to obtain CHIRPS rasters, set the argument output_raster equal to TRUE.\n\n#Obtain daily rainfall rasters for 2012-01-01 through 2012-01-31\nrain_areal_raster <- daily_rainfall(c(start_date, end_date), shp, output_raster = TRUE)\n\n#Plot raster for January 1, 2012\nterra::plot(rain_areal_raster$`chirps_2012-01-01`)"
  },
  {
    "objectID": "posts/rainfall/index.html#point-data",
    "href": "posts/rainfall/index.html#point-data",
    "title": "Downloading CHIRPS rainfall data",
    "section": "Point data",
    "text": "Point data\nTo get estimated daily rainfall at specified locations, such as health facilities, we can use the chirps package. Here, we’ll create a data.frame of points and download their data.\n\ninstall.packages(\"chirps\", repos = \"http://cran.us.r-project.org\")\n\npackage 'chirps' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\eferriss\\AppData\\Local\\Temp\\RtmpwjwdPW\\downloaded_packages\n\nlibrary(chirps)\n\n#Create points object\npoints <- data.frame(lon = c(28.287, 28.213, 28.637, 28.446), lat = c(-15.407, -12.802, -12.959, -14.447))\n\n#Obtain daily rainfall for 2012-01-01 through 2012-01-31\nstart_date <- \"2012-01-01\"\nend_date <- \"2012-01-31\"\nrain_point <- get_chirps(points, c(start_date, end_date), server = \"ClimateSERV\")\n\n#View first few rows\nhead(rain_point)\n\n      id   lon    lat       date chirps\n   <int> <dbl>  <dbl>     <date>  <dbl>\n1:     1 28.29 -15.41 2012-01-01  14.62\n2:     1 28.29 -15.41 2012-01-02   7.31\n3:     1 28.29 -15.41 2012-01-03   0.00\n4:     1 28.29 -15.41 2012-01-04   0.00\n5:     1 28.29 -15.41 2012-01-05   0.00\n6:     1 28.29 -15.41 2012-01-06   0.00"
  },
  {
    "objectID": "posts/rainfall/index.html#aggregating-data-from-daily-to-monthly",
    "href": "posts/rainfall/index.html#aggregating-data-from-daily-to-monthly",
    "title": "Downloading CHIRPS rainfall data",
    "section": "Aggregating data from daily to monthly",
    "text": "Aggregating data from daily to monthly\nTo get monthly data, we aggregate the above objects.\n\nlibrary(tidyverse)\nlibrary(lubridate)\n\n#Aggregate areal data to monthly totals\nrain_areal_long_monthly <- rain_areal_long %>%\n  group_by(ADM1, month = floor_date(date, \"month\")) %>%\n  summarise(rainfall = sum(rainfall))\n\nrain_areal_long_monthly\n\n# A tibble: 10 × 3\n# Groups:   ADM1 [10]\n   ADM1         month      rainfall\n   <chr>        <date>        <dbl>\n 1 Central      2012-01-01     253.\n 2 Copperbelt   2012-01-01     325.\n 3 Eastern      2012-01-01     325.\n 4 Luapula      2012-01-01     259.\n 5 Lusaka       2012-01-01     237.\n 6 Muchinga     2012-01-01     265.\n 7 Northern     2012-01-01     219.\n 8 Northwestern 2012-01-01     237.\n 9 Southern     2012-01-01     163.\n10 Western      2012-01-01     172.\n\n#Aggregate point data to monthly totals\nrain_point_monthly <- rain_point %>%\n  group_by(lon, lat, month = floor_date(date, \"month\")) %>%\n  summarise(chirps = sum(chirps))\n\nrain_point_monthly\n\n# A tibble: 4 × 4\n# Groups:   lon, lat [4]\n    lon   lat month      chirps\n  <dbl> <dbl> <date>      <dbl>\n1  28.2 -12.8 2012-01-01   321.\n2  28.3 -15.4 2012-01-01   214.\n3  28.4 -14.4 2012-01-01   269.\n4  28.6 -13.0 2012-01-01   330."
  },
  {
    "objectID": "posts/elevation-rasters/index.html",
    "href": "posts/elevation-rasters/index.html",
    "title": "Downloading elevation data in R",
    "section": "",
    "text": "We will be using a relatively new R package called whatarelief. This package is hosted on Github, but is not currently on CRAN so we have to use the devtools package to install (you may need to install this package first).\nThe primary function in this package is called elevation(), which downloads a elevation raster directly into our R session. This raster can be automatically formatted for specific locations using a reference extent, shapefile, or other raster file.\nThe package documentation provide all the information you’ll need to get started, including how to select difference elevation sources. It’s worth looking through the documentation, as there are some quarks.\n\nlibrary(whatarelief)\nimage(im <- elevation())\n\n[1] \"/vsicurl/https://public.services.aad.gov.au/datasets/science/GEBCO_2019_GEOTIFF/GEBCO_2019.tif\"\n\n\n\n\n\n\n\n\nimage(t(im[nrow(im):1, ]))\n\n\n\n\n\n\n\n\nThe next section will demonstrate a brief example for getting elevation data from Zambia"
  },
  {
    "objectID": "posts/elevation-rasters/index.html#example-elevation-raster-for-zambia",
    "href": "posts/elevation-rasters/index.html#example-elevation-raster-for-zambia",
    "title": "Downloading elevation data in R",
    "section": "Example: Elevation raster for Zambia",
    "text": "Example: Elevation raster for Zambia\nTo get started, let’s load some useful packages for working with rasters and shapefiles, then we will download a shapefile for Zambia.\n\nlibrary(raster)   # Raster package\nlibrary(sf)       # Shapefile package\nlibrary(PATHtoolsZambia)  # PATH data for Zambia\n\n# Load reference shapefile\nshp <- retrieve(\"province-shp\")\n\n# Load reference raster\nrst <- retrieve(\"grid3-pop-rescaled\")\n\n# Visualize\nplot(rst, col = viridis::plasma(100))\nplot(st_geometry(shp), add = T)\n\n\n\n\n\n\n\n\nTo use a reference raster to select an area for interest, all we need to do is include the raster object in the elevation() functions.\n\nzm_elv1 <- elevation(rst)\n\n[1] \"/vsicurl/https://public.services.aad.gov.au/datasets/science/GEBCO_2019_GEOTIFF/GEBCO_2019.tif\"\n\nplot(zm_elv1)\nplot(st_geometry(shp), add = T)\n\n\n\n\n\n\n\n\nConveniently, this elevation raster is at the same resolution and alignment as our reference.\n\ncompareRaster(rst, zm_elv1)\n\n[1] TRUE\n\nstack(rst, zm_elv1)\n\nclass      : RasterStack \ndimensions : 1177, 1406, 1654862, 2  (nrow, ncol, ncell, nlayers)\nresolution : 0.008333333, 0.008333333  (x, y)\nextent     : 21.99542, 33.71208, -18.07958, -8.27125  (xmin, xmax, ymin, ymax)\ncrs        : +proj=longlat +datum=WGS84 +no_defs \nnames      : grid3_1km_rescaled.1, grid3_1km_rescaled.2 \nmin values :             1.042396,           118.241821 \nmax values :            30135.733,             2726.069 \n\n\nTo test this functionality, let’s aggregate our reference raster and get a new elevation raster.\n\n# Aggregate by a factor of 5\nrst_agg <- aggregate(rst, 5, fun = \"sum\")\nplot(rst_agg, col = viridis::plasma(100))\nplot(st_geometry(shp), add = T)\n\n\n\n\n\n\n\n# Pull aggregated version of elevation \nzm_elv2 <- elevation(rst_agg)\n\n[1] \"/vsicurl/https://public.services.aad.gov.au/datasets/science/GEBCO_2019_GEOTIFF/GEBCO_2019.tif\"\n\nplot(zm_elv2)\nplot(st_geometry(shp), add = T)\n\n\n\n\n\n\n\n# Compare\ncompareRaster(rst_agg, zm_elv2)\n\n[1] TRUE\n\nstack(rst_agg, zm_elv2)\n\nclass      : RasterStack \ndimensions : 236, 282, 66552, 2  (nrow, ncol, ncell, nlayers)\nresolution : 0.04166667, 0.04166667  (x, y)\nextent     : 21.99542, 33.74542, -18.10458, -8.27125  (xmin, xmax, ymin, ymax)\ncrs        : +proj=longlat +datum=WGS84 +no_defs \nnames      : grid3_1km_rescaled.1, grid3_1km_rescaled.2 \nmin values :             1.065404,           131.133560 \nmax values :           226794.442,             2450.497 \n\ntry(compareRaster(zm_elv1, zm_elv2))\n\nError in compareRaster(zm_elv1, zm_elv2) : different extent\n\n\nIt is also possible to download rasters using just the extent as a numeric vector, which means it is also possible to use a shapefile. However, you will also have to provide the projection and potential other spatial information, which may be more difficult than just using a reference raster."
  },
  {
    "objectID": "posts/urban-rural-pathtools/index.html",
    "href": "posts/urban-rural-pathtools/index.html",
    "title": "Defining urban areas based on population rasters",
    "section": "",
    "text": "This process uses an R package developed by PATH. This package is hosted on Github, so we have to use the devtools package to install it (you may need to install this package first).\n\ninstall.packages(\"devtools\")\ndevtools::install_github(\"PATH-Global-Health/PATHtools\")\n\nThe primary function in this package that we will use is define_urban(), which defines rural and urban areas based on population density.\nThe function requires a population density raster which is a gridded population surface, representing population distribution. We will download this from the GRID3 data repository."
  },
  {
    "objectID": "posts/urban-rural-pathtools/index.html#downloading-grid3-population-rasters",
    "href": "posts/urban-rural-pathtools/index.html#downloading-grid3-population-rasters",
    "title": "Defining urban areas based on population rasters",
    "section": "Downloading GRID3 population rasters",
    "text": "Downloading GRID3 population rasters\nWe will use Senegal as an example - the download links for other countries with GRID3 population data avaliable can be found in the code block below for reference.\n\n#  Sierra Leone: https://wopr.worldpop.org/download/473\n#  South Sudan: https://wopr.worldpop.org/download/344\n#  Mozambique: https://wopr.worldpop.org/download/237\n#  DRC - Kinshasa, Kongo-Central, Kwango, Kwilu, and Mai-Ndombe provinces: https://wopr.worldpop.org/download/113\n#  DRC - Haut-Katanga, Haut-Lomami, Ituri, Kasaï, Kasaï Oriental, Lomami and Sud-Kivu provinces: https://wopr.worldpop.org/download/488\n#  Niger: https://wopr.worldpop.org/download/511\n#  Burkina Faso: https://wopr.worldpop.org/download/515\n#  Nigeria: https://wopr.worldpop.org/download/495\n#  Zambia: https://wopr.worldpop.org/download/25\n\nFirst we load some useful packages for working with rasters and shapefiles, then we will download the populaiton raster file for Senegal. The GRID3 population raster is at a resolution of 100m so we need to use the aggregate() function from the terra package to combine grid cells to a spatial resolution of 1km grid cells for input into the define_urban() function.\n\nlibrary(raster)        # Raster package\nlibrary(terra)         # Terra package\nlibrary(exactextractr) # exactextractr package\nlibrary(sf)            # Shapefile package\nlibrary(CHWplacement)  # CHWplacement pakacge\nlibrary(tidyverse)     # Tidyverse \nlibrary(tidyterra)     # Tidyverse methods for terra objects\nlibrary(ggforce)       # ggforce package for facet zooming \nlibrary(PATHtools)     # PATHtools package for retriving shapefiles\nlibrary(fs)            # file system package\n\n# Load reference shapefile\nshp <- PATHtools::load_shapefile(country = \"Senegal\", admin_level = 1)\n\n# Grid3 raster URL \nurl <- \"https://wopr.worldpop.org/download/502\" # url for Senegal raster\n\n# Create a temporary folder for downloaded raster\ndest <- tempdir()\n\n# file name \nfile_name <- fs::path(dest, \"grid3-pop-raster.tif.gz\")\n\n# download and unzip the raster file \nutils::download.file(url = url, destfile = file_name, mode = \"wb\", quiet = TRUE)\nR.utils::gunzip(file_name)\n\n# load raster into R session\npopulation_100m <- terra::rast(fs::path(dest, \"grid3-pop-raster.tif\")) \n\n# aggregate population raster from 100m grid cell resolution to 1km grid cell resolution \npopulation_1km <- terra::aggregate(population_100m, fact=10, na.rm=TRUE, fun = \"sum\")\n\n# plot population per km \nggplot() +\n  geom_spatraster(data = population_1km) +\n  scale_fill_whitebox_c(palette = \"deep\", direction = -1) +\n  theme_grey() +\n  labs(title = \"GRID3 population per 1km Senegal 2020\", fill=\" \") +\n  facet_zoom(xlim=c(-17,-17.6), ylim=c(14.5,15), horizontal = TRUE, shrink=TRUE, zoom.size =0.8) +\n  theme(axis.text = element_blank(), \n        axis.ticks = element_blank(), \n        panel.grid = element_blank())\n\n\n\n\n\n\n\n\nThe resulting plot displays the populated areas of Senegal with those areas in yellow representing the most densely populated areas with the panel highlighting Dakar - the capital city of Senegal.\nIn this example I created a temporary folder (using the tempdir()) and saved it’s “path” into an object called dest. This is where we will download rasters. You can swap tempdir() with a file path to a location on your computer. Or directly read in a raster if it is already avaliable on your computer."
  },
  {
    "objectID": "posts/urban-rural-pathtools/index.html#classification-of-urban-and-rural-areas",
    "href": "posts/urban-rural-pathtools/index.html#classification-of-urban-and-rural-areas",
    "title": "Defining urban areas based on population rasters",
    "section": "Classification of urban and rural areas",
    "text": "Classification of urban and rural areas\n\n\n\n\n\nContigious grid cells. The grid displays a central coloured cell surrounded by 8 other cells numbered 1 through 8. four-point contiguity would select grid cells 2,4,6 and 8 as contigious to the central cell. eight-point contiguity would select all grid cells 1 through 8 as contigious, as this definition also allows grid cells that are linked on the diagonal.\n\n\nThe next step in this work is to use the define_urban() function from the PATHtools pacakge to define urban areas. This is done using 1km² grid cells, classified according to their population density, population size and contiguity (neighbouring cells).\nThis function requires 3 inputs:\n\npopulation_raster: An input raster containing people per pixel. Default inputs assume input resolution to be approximately 1km² resolution\nrururb_cutoff: indicates the minimum population per pixel to be eligible for urban classification\nmin_urbsize: indicates the minimum population in the total area of contiguous selected pixels to be considered as urban\n\nThe identification of urban areas then occurs in two steps, first all cells with a population density of over runurb_cutoff are selected and then groups of contigious cells are identified using eight-point contiguity, in other words, including diagonals (see margin figure). Contigious cells are grouped together and each group with a collective population size of over min_urbsize are defined as urban.\nFor this example we use a population density threshold of 300 people per square km (rururb_cutoff) and a minimum population size (min_urbsize) of 10,000 people.\nThese values were selected based on the smallest population density threshold used to define an urban area from the Level 1 definitions in Eurostat: Applying the Degree of Urbanisation — A methodological manual to define cities, towns and rural areas for international comparisons — 2021 edition and the value of 10,000 came from the national definition of an urban area as listed in the UN Demographic Year Book 2021.\n\n# run function to define urban clusters\n\n# this first function call we set mask == FALSE to output a raster with only urban cells and their associated population values\nur_population <- define_urban(population_1km, min_urbsize = 10000, rururb_cutoff = 300, mask = FALSE)\n\n# this second function call we set mask == TRUE to output a raster that defines each pixel as urban (1) or rural (0)\nur_categories <- define_urban(population_1km, min_urbsize = 10000, rururb_cutoff = 300, mask = TRUE) \ncls <- data.frame(id=c(1, 0), urban_rural=c(\"urban\", \"rural\"))\nlevels(ur_categories) <- cls\n\nThe function outputs a new raster which we have saved as an object in our R session called ur_population and ur_categories. This first is a raster is similar to population_raster input but all non-urban pixels are masked (i.e. NA). And the second a raster that classifies populated pixels as either urban or rural.\n\n\n\n\n\ndefine_urban() function outputs\n\n\n\n\n\n\n\n\n\nFor performing this analysis for another country users can use the threshold values from the Eurostat manual, or if a national threshold is provided the user can select these. The Eurostat manual uses two definitions of urban at a level 1 classification.\n\nUrban centre (high density cluster) - a cluster of contiguous grid cells of 1km² (using four-point contiguity, in other words, excluding diagonals. To perform 4 point contiguity in the define_urban() function set directions = 4 in the function call) with a population density of at least 1,500 inhabitants per km² and collectively a minimum population of 50,000 inhabitants before gap-filling.\nUrban cluster (moderate-density cluster) — a cluster of contiguous grid cells of 1 km² (using eight-point contiguity, in other words, including diagonals) with a population density of at least 300 inhabitants per km² and a minimum population of 5,000 inhabitants."
  },
  {
    "objectID": "posts/urban-rural-pathtools/index.html#calculating-the-urban-proportion-of-the-population-in-a-spatial-area-defined-by-an-input-shape-file",
    "href": "posts/urban-rural-pathtools/index.html#calculating-the-urban-proportion-of-the-population-in-a-spatial-area-defined-by-an-input-shape-file",
    "title": "Defining urban areas based on population rasters",
    "section": "Calculating the urban proportion of the population in a spatial area defined by an input shape file",
    "text": "Calculating the urban proportion of the population in a spatial area defined by an input shape file\nTo calcualte the proportion of the population in a spatial region that live in urban or rural areas we first need a shape file with defined boundaries e.g. administrative units or health facility catchment areas.\nFor this example we will use a shapefile of the 14 regions of Senegal.\n\n# crop the raster to the shape file outline of senegal to ensure extents match \nur_population <- crop(ur_population, extent(shp))\nur_population <- mask(ur_population, shp)\n\n# for ID-ing regions\nsf_tibble <- tibble::as_tibble(sf::st_drop_geometry(shp))\n\n# extract the full GRID3 population to admin-1 units \nadm1_pop <-\n    exactextractr::exact_extract(population_1km, shp, 'sum', progress = FALSE) %>% \n    dplyr::bind_cols(sf_tibble) %>% \n    dplyr::select(ADM1, total_pop = ...1)\n  \n# extract urban population to admin-1 units  \nadm1_urb_pop <- \n    exactextractr::exact_extract(ur_population, shp, 'sum', progress = FALSE) %>% \n    dplyr::bind_cols(sf_tibble) %>% \n    dplyr::select(ADM1, urban_pop = ...1)\n\n# join dataframes together and calculate proportion of the population in urban areas per admin-1 units \nurb_pop_prop <- \n  left_join(adm1_pop, adm1_urb_pop) %>% \n  mutate(prop_ur = urban_pop / total_pop) %>% \n  mutate(prop_ur = case_when(is.na(prop_ur) ~ 0, TRUE ~ prop_ur))\n\n# plot the proportion of the population living in urban areas by admin-1 units \nshp_pop <- \n  shp %>% \n  left_join(urb_pop_prop) \n\nggplot(shp_pop) +\n  geom_sf(aes(fill=prop_ur*100), col=NA) +\n  scale_fill_whitebox_c(palette= \"deep\") +\n  theme_gray(10) +\n  theme(axis.text = element_blank(), \n        axis.ticks = element_blank(), \n        panel.grid = element_blank(),\n        legend.position=\"bottom\", \n        legend.key.width = unit(2, 'cm')) +\n  labs(fill=\"%\", title=\"Proprtion of the population living in urban areas 2020\")"
  },
  {
    "objectID": "posts/urban-rural-pathtools/index.html#classifying-point-locations-based-on-urban-rural-pixel-classifications",
    "href": "posts/urban-rural-pathtools/index.html#classifying-point-locations-based-on-urban-rural-pixel-classifications",
    "title": "Defining urban areas based on population rasters",
    "section": "Classifying point locations based on urban rural pixel classifications",
    "text": "Classifying point locations based on urban rural pixel classifications\nIf geo-location or point data is avaliable, for example the co-ordinates of health facilities, hospitals, schools, pharmacies etc, then we can use the ur_categories raster output to classify these services and the communities they serve.\nHere I create some example coordinates but users should upload their own coordinates of interest here. In this example we include a 2.5km buffer region around each point to account for potential heterogeneity that might be missed from taking just the point-level extraction.\n\n# example coordinates \npoints <- data.frame(name = c(\"a\", \"b\", \"c\", \"d\"), \n                     latitude = c(14.72810, 15.01430, 15.99420, 12.67370), \n                     longitude = c(-17.45910, -12.50030, -15.32010, -16.09250))\n\n# transform to a spatial object \npoints   <- sf::st_as_sf(points,                                # first argument = data frame with coordinates\n                          coords = c(\"longitude\", \"latitude\"),  # name of columns, in quotation marks\n                          crs = 4326)                           # coordinate reference system to make sense of the numbers\n\n# include a 2.5km buffer region around point location   \npoints_w_buffer <- terra::vect(points) %>% terra::buffer(width=2500) \n\nBecause we include a buffer region we will then take the mode of the extracted cell values for each of our locations. The following function calculates and returns the mode of the categorical extraction variables.\n\ncalculate_mode <- function(x) {\n  uniqx <- unique(na.omit(x))\n  uniqx[which.max(tabulate(match(x, uniqx)))]\n}\n\nNow we can run the extraction and examine the resulting classification.\n\n# crop the raster to the shape file outline of senegal to ensure extents match \nur_categories <- crop(ur_categories, extent(shp))\nur_categories <- mask(ur_categories, shp)\n\n# extraction\npoints_classification <- \n  terra::extract(ur_categories, points_w_buffer) %>%\n  dplyr::group_by(ID) %>%\n  dplyr::summarise(dplyr::across(dplyr::everything(), list)) %>%\n  tidyr::unnest(cols = c(urban_rural)) %>%\n  dplyr::group_by(ID) %>%\n  dplyr::summarize(classification = calculate_mode(urban_rural)) \n\n# as a spatial object\npoints_classification_sf <- bind_cols(points, points_classification)\n\n# plot \nggplot() +\n  geom_spatraster(data = ur_categories) +\n  geom_sf(data = points_classification_sf, mapping=aes(col=classification), shape = 19,\n          fill=NA, size=1)+\n  theme_grey(12) +\n  labs(title = \"\", fill=\" \", col=\" \") +\n  scale_color_manual(values=c(\"#b01f35\", \"#C6EBC5\"),\n                     labels=c(\"urban\", \"rural\"), breaks=c(\"urban\", \"rural\")) +\n  scale_fill_manual(values=c(\"#FA7070\", \"#4f7942\"), \n                    labels=c(\"urban\", \"rural\"), breaks=c(\"urban\", \"rural\")) +\n  theme(axis.text = element_blank(),\n        axis.ticks = element_blank(),\n        panel.grid = element_blank(),\n        legend.position=\"bottom\")"
  },
  {
    "objectID": "posts/modistsp/index.html",
    "href": "posts/modistsp/index.html",
    "title": "Downloading MODIS raster data in R with MODIStsp",
    "section": "",
    "text": "The MODIStsp package provides an R interface to the raster images derived from MODIS Land Products data. This package provides an interactive user interface, as well as functions for programmatic queries for the time-series rasters. Note that this library requires and active internet connection.\nBefore installing the package, be sure that you have an NASA EarthData account, which is free and can be created at https://urs.earthdata.nasa.gov/home.\nOnce you have an active account, you can install the MODIStsp package directly from CRAN.\n\ninstall.packages(\"MODIStsp\")\n\nYou can also install the experimental version of the package from the MODIStsp Github repository. The package has excellent documentation, including multiple example articles. The following sections will briefly demonstrate the interactive and non-interactive modes, but be sure to check the package documentation for more details!"
  },
  {
    "objectID": "posts/modistsp/index.html#interactive-interface",
    "href": "posts/modistsp/index.html#interactive-interface",
    "title": "Downloading MODIS raster data in R with MODIStsp",
    "section": "Interactive interface",
    "text": "Interactive interface\nThe main function in the MODIStsp package is called MODIStsp(). By default, running this function with any additional input will launch the interactive graphic user interface (GUI) in you web browser.\n\n# Load library\nlibrary(MODIStsp)\n\n# Launch graphic interface \nMODIStsp()\n\n\n\n\nScreenshot of MODIStsp graphic user interface\n\n\nThis GUI will lead to step-by-step through the selection, processing, and outputting workflow.\nStarting with the “Products and Layers” section, choose which MODIS product and remote sensed layers you wish to download. Multiple layers can be included for a selected product category. The ? mark icon provide useful information on the various inputs, and the book button next to the Product Name menu will link to the NASA product documentation page, which will contains further details for that product including units, resolution, and aggregation scale factor.\nOnce the products layers have been selected, move onto the “Spatial/Temporal option” section. Here you can select the time range, projection, and spatial extent. Spatial parameters can be defined by tile selection, bounding box, uploading a shapefile, or by drawing on an interactive map.\nNext, move to the “Output Format and Folders” section. This is where you will provide your NASA EarthData user information, and set the destination for your output files. You can use the “Browse” button to selection the output folder on your computer.\nOnce you have filled out each section you can press the “Run MODIStsp” button on the left menu. This will execute your query and process the download. Download times will depend on your input parameters and internet connection."
  },
  {
    "objectID": "posts/modistsp/index.html#programmatic-mode",
    "href": "posts/modistsp/index.html#programmatic-mode",
    "title": "Downloading MODIS raster data in R with MODIStsp",
    "section": "Programmatic mode",
    "text": "Programmatic mode\nWhile the interactive GUI approach may be useful for individual data pulls, you may want to programmatic define your download parameters. This is especially useful to embed within code for analysis, as it serves as documentation and improves reproducibility.\nThe package documentation also provides an article for using the programmatic approach. This uses the same MODIStsp() function, expect now we have to provide the inputs that we would have used in the GUI directly into the function.\nHere is an example for getting monthly NDVI and EVI rasters for Zambia 2021. First we still start by downloading a shapefile for Zambia.\n\n# Load libraries\nlibrary(fs)         # File management package\nlibrary(sf)         # Spatial data package\nlibrary(raster)     # Raster data package\nlibrary(MODIStsp)   # MODIS package\nlibrary(tidyverse)  # Data process and viz\n\n# Create a temporary folder for downloaded files\ndest <- tempdir()\n\n# Download shapefile for Zambia\nshp_url <- paste0(\"https://raw.githubusercontent.com/\", \n                  \"PATH-Global-Health/geometries/main/adm0/Zambia/adm0.json\")\ndownload.file(url = shp_url, destfile = path(dest, \"Zambia.json\"))\nshp <- st_geometry(st_read(path(dest, \"Zambia.json\"), quiet = T))\nplot(shp)\n\n\n\n\n\n\n\n\nIn this example I created a temporary folder (using the tempdir()) and saved it’s “path” into an object called dest. This is where we will download rasters and other metadata files. You can swap tempdir() with a file path to a location on your computer.\nNext, use the MODIStsp() function to download rasters by setting each parameter within the function. Here is the code for download monthly NDVI and EVI raster for 2021 at a 1 kilometer resolution.\n\n\n\n\n\n\nTime consuming function\n\n\n\nThis function may take several minutes or longer to run depending on the number of rasters, their sizes and resolutions, and your internet. Setting parallel = TRUE can help speed up the download.\n\n\n\n\n\n\n# user and pass are set based on NASA EarthData account credentials\nMODIStsp(\n  gui             = FALSE,\n  out_folder      = dest,\n  selprod         = \"Vegetation_Indexes_Monthly_1Km (M*D13A3)\",\n  bandsel         = c(\"NDVI\", \"EVI\"),\n  sensor          = \"Terra\",\n  spatmeth        = \"file\",\n  spafile         = path(dest, \"Zambia.json\"),\n  output_proj     = \"+proj=longlat +datum=WGS84 +no_defs\",\n  start_date      = \"2021.01.01\",\n  end_date        = \"2021.12.31\",\n  user            = user,\n  password        = pass,\n  verbose         = FALSE,\n  parallel        = TRUE\n)\n\nThere are a lot of details, but remeber that we have to supply everything that we would have clicked in the GUI. The benefit of this approach is that we can save it in a script, which means the our process is documented and repeatable.\n\nDefining product, layers, and sensor\nWe need to tell R which MODIS product and which specific layers from that product we want to download. We do this using the selprod and bandsel arguments, respectively. We can only select one MODIS product at a time, but we can download multiple layers from that product at once.\nYou can use the MODIStsp_get_prodnames() function to list the available MODIS products, and the MODIStsp_get_prodlayers() function to get a list of available layers.\nFinally, we can choose to select layers from either the Terra or Aqua sensors. The default is to pull from both (if both are available), which is fine but may be unnecessary and will take extra time then selecting an individual sensor.\n\n\nDefining spatial extent and projection\nSimilar to the GUI, there are multiple options for defining the spatial extent, include using a local shapefile (\"file\"), the bounding box of a spatial object (\"bbox\"), or specific tile number from the MODIS Grid (\"tile\"). While each approach is viable, I’ve had the most success with the \"file\" method.\nWe can also set the geographic projection for the rasters using the output_proj argument. This is helpful if the default projection from MODIS does not match other spatial data, such as our shapefile.\n\n\nDefining time frame and user credentials\nNext, we state the time frame for our raster pulls. The number of raster files that will be download within this time frame will depend on the selected product. The input format is a character string with the format \"YYYY-MM-DD\", not an as.Date() or lubridate-style date.\nWe also need to supply your username and password for your NASA EarthData account. In this example, I save this information into variables called user and pass, which I defined directly in the R Console rather than in my script, that way any personal credential information is not saved within my script.\nFinally, there are many additional arguments that can be included. Some helpful ones are verbose = TRUE, which will print information in your Console during through downloading, and parallel = TRUE, which will speed up the download by using multiple CPU cores.\n\n\nLoading and plotting data\nLet’s data a look at the files in our dest output folder. Since we defined the extent using a shapefile called Zambia.json, the MODIStsp() function created a new folder called Zambia and stored all the of results here. These are all of the raster files that we downloaded.\n\ndir_ls(path(dest, \"Zambia\"), recurse = T, type = \"file\") %>% \n  path_rel(dest)  # This function returns the \"relative\" path\n\nZambia/MODIStsp_2022-07-26.json\nZambia/VI_Monthly_1Km_v6/EVI/MOD13A3_EVI_2021_001.tif\nZambia/VI_Monthly_1Km_v6/EVI/MOD13A3_EVI_2021_032.tif\nZambia/VI_Monthly_1Km_v6/EVI/MOD13A3_EVI_2021_060.tif\nZambia/VI_Monthly_1Km_v6/EVI/MOD13A3_EVI_2021_091.tif\nZambia/VI_Monthly_1Km_v6/EVI/MOD13A3_EVI_2021_121.tif\nZambia/VI_Monthly_1Km_v6/EVI/MOD13A3_EVI_2021_152.tif\nZambia/VI_Monthly_1Km_v6/EVI/MOD13A3_EVI_2021_182.tif\nZambia/VI_Monthly_1Km_v6/EVI/MOD13A3_EVI_2021_213.tif\nZambia/VI_Monthly_1Km_v6/EVI/MOD13A3_EVI_2021_244.tif\nZambia/VI_Monthly_1Km_v6/EVI/MOD13A3_EVI_2021_274.tif\nZambia/VI_Monthly_1Km_v6/EVI/MOD13A3_EVI_2021_305.tif\nZambia/VI_Monthly_1Km_v6/EVI/MOD13A3_EVI_2021_335.tif\nZambia/VI_Monthly_1Km_v6/NDVI/MOD13A3_NDVI_2021_001.tif\nZambia/VI_Monthly_1Km_v6/NDVI/MOD13A3_NDVI_2021_032.tif\nZambia/VI_Monthly_1Km_v6/NDVI/MOD13A3_NDVI_2021_060.tif\nZambia/VI_Monthly_1Km_v6/NDVI/MOD13A3_NDVI_2021_091.tif\nZambia/VI_Monthly_1Km_v6/NDVI/MOD13A3_NDVI_2021_121.tif\nZambia/VI_Monthly_1Km_v6/NDVI/MOD13A3_NDVI_2021_152.tif\nZambia/VI_Monthly_1Km_v6/NDVI/MOD13A3_NDVI_2021_182.tif\nZambia/VI_Monthly_1Km_v6/NDVI/MOD13A3_NDVI_2021_213.tif\nZambia/VI_Monthly_1Km_v6/NDVI/MOD13A3_NDVI_2021_244.tif\nZambia/VI_Monthly_1Km_v6/NDVI/MOD13A3_NDVI_2021_274.tif\nZambia/VI_Monthly_1Km_v6/NDVI/MOD13A3_NDVI_2021_305.tif\nZambia/VI_Monthly_1Km_v6/NDVI/MOD13A3_NDVI_2021_335.tif\nZambia/VI_Monthly_1Km_v6/Time_Series/RData/Terra/EVI/MOD13A3_EVI_1_2021_335_2021_RData.RData\nZambia/VI_Monthly_1Km_v6/Time_Series/RData/Terra/NDVI/MOD13A3_NDVI_1_2021_335_2021_RData.RData\n\n\nHere we can see more of the default naming conventions. Inside the Zambia folder we have a JSON file the contains the details for the API call that downloaded our raster, and a folder called VI_Monthly_1Km_v6, which matches our selected MODIS product. Inside VI_Monthly_1Km_v6 there are two folders, NDVI and EVI, which are the bandnames for our selected layers. Inside these subfolders, there are 12 .tif raster files. The naming convention for these files is PRODNAME_PRODLAYER_YYYY_DDD.tif where DDD refers to the Julian calendar date (1 to 365) for the starting date for that layer.\nThere is also a Time_Series subfolder, which contains a .RData file containing a RasterStack object for each layer. Loading this file with load() will an load this object with the default name of raster_ts .\nWe can load individual rasters into R, and use them from plotting and/or further analysis.\n\n# Load one raster file from the \"NDVI\" folder\nrst <- raster(dir_ls(path(dest, \"Zambia\", \"VI_Monthly_1Km_v6\", \"NDVI\"))[1])\n\n# Plot\nplot(rst)\nplot(shp, add = T, lwd = 2)\n\n\n\n\n\n\n\n\nYou might notice that the values for this raster are much larger than we would expect for NDVI (which ranges from -1 to 1). If we look in the MODIS Data Catalog for the documentation on this layer we can see that the scale factor for the NDVI layer is 0.0001, meaning that we will want to multiple the raster values by this constant to return the actual values. Next time we pull this raster layer using MODIStsp() we may want to set the scale_val argument to 0.0001 to make this adjustment automatically.\nFinally, since all of the rasters are pulled using the same criteria (other the date), they should align. This means that we can use the stack() function to create a RasterStack.\n\nrst_stack <- stack(dir_ls(path(dest, \"Zambia\", \"VI_Monthly_1Km_v6\", \"NDVI\")))\nplot(rst_stack)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This blog contains technical documentation for various process that PATH and our collaborators may find useful for reproducing and extending analyses.\nIf you are interested in contributing, please provide a pull request via Github. Please make sure the sensitive data is removed or properly anonymized."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PATH Malaria & NTDs Technical Docs",
    "section": "",
    "text": "Downloading CHIRPS rainfall data\n\n\n\n\n\n\n\nrainfall\n\n\nR\n\n\nraster\n\n\n\n\n\n\n\n\n\n\n\nMar 1, 2023\n\n\nWill Sheahan, Justin Millar, and Ellen Ferriss\n\n\n\n\n\n\n  \n\n\n\n\nDefining urban areas based on population rasters\n\n\n\n\n\n\n\nR\n\n\nraster\n\n\nurbanization\n\n\n\n\n\n\n\n\n\n\n\nDec 20, 2022\n\n\nHayley Thompson\n\n\n\n\n\n\n  \n\n\n\n\nDownloading MODIS raster data in R with MODIStsp\n\n\n\n\n\n\n\nremote sensing\n\n\nR\n\n\nraster\n\n\n\n\n\n\n\n\n\n\n\nJul 25, 2022\n\n\nJustin Millar\n\n\n\n\n\n\n  \n\n\n\n\nDownloading elevation data in R\n\n\n\n\n\n\n\nremote sensing\n\n\nR\n\n\nraster\n\n\n\n\n\n\n\n\n\n\n\nJul 13, 2022\n\n\nJustin Millar\n\n\n\n\n\n\nNo matching items"
  }
]